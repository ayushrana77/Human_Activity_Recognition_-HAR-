{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":793070,"sourceType":"datasetVersion","datasetId":226}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import LinearSegmentedColormap\nimport itertools\nfrom sklearn.utils import class_weight\n# Print TensorFlow version for debugging\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"_uuid":"fd1d447e-d702-4582-8998-69fb9ff9e984","_cell_guid":"ae50315b-10d0-40e0-954e-cd10fa56352f","trusted":true,"collapsed":false,"id":"q4qoLVYzMXNY","execution":{"iopub.status.busy":"2025-03-22T11:33:00.138787Z","iopub.execute_input":"2025-03-22T11:33:00.139148Z","iopub.status.idle":"2025-03-22T11:33:00.144497Z","shell.execute_reply.started":"2025-03-22T11:33:00.139122Z","shell.execute_reply":"2025-03-22T11:33:00.143326Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.17.1\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"np.random.seed(42)\ntf.random.set_seed(42)\n\n# Configure TensorFlow session for reproducibility\n# Simplified approach that works across TF versions\ntry:\n    # For TF 1.x compatibility\n    tf.compat.v1.disable_eager_execution()\n    session_conf = tf.compat.v1.ConfigProto(\n        intra_op_parallelism_threads=1,\n        inter_op_parallelism_threads=1\n    )\n    tf.compat.v1.set_random_seed(42)\n    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n    # Don't try to set session in Keras backend - it's not needed in newer versions\nexcept:\n    print(\"Using TF 2.x behavior with deterministic operations\")\n    # For TF 2.x, use these settings instead\n    tf.config.threading.set_inter_op_parallelism_threads(1)\n    tf.config.threading.set_intra_op_parallelism_threads(1)\n    tf.config.experimental.enable_op_determinism()\n\n# Importing libraries\n# Use tensorflow.keras instead of keras for better compatibility\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import LSTM, TimeDistributed, Conv1D, MaxPooling1D, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Bidirectional, Input, SpatialDropout1D, Concatenate, Add, Reshape, GlobalAveragePooling1D\nfrom tensorflow.keras.layers import SeparableConv1D, MultiHeadAttention, LayerNormalization, Attention\nfrom tensorflow.keras.layers import AveragePooling1D\nfrom tensorflow.keras.layers import Multiply\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import to_categorical","metadata":{"_uuid":"940d6b5b-b3ec-47ed-8f89-0d5ed03b922e","_cell_guid":"afd8bb26-0fd3-4ec4-88c8-79cf7870df40","trusted":true,"collapsed":false,"id":"zHM5H76NN3-Z","execution":{"iopub.status.busy":"2025-03-22T11:33:00.145787Z","iopub.execute_input":"2025-03-22T11:33:00.146058Z","iopub.status.idle":"2025-03-22T11:33:00.170330Z","shell.execute_reply.started":"2025-03-22T11:33:00.146038Z","shell.execute_reply":"2025-03-22T11:33:00.169628Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"\"\"\"### Load Data\"\"\"\n\n# Data directory for Kaggle\nDATADIR = '/kaggle/input/human-activity-recognition-with-smartphones'\n\n# Activity labels\nACTIVITIES = {\n    1: 'WALKING',\n    2: 'WALKING_UPSTAIRS',\n    3: 'WALKING_DOWNSTAIRS',\n    4: 'SITTING',\n    5: 'STANDING',\n    6: 'LAYING'\n}\n\n# Raw data signals\n# Signals are from Accelerometer and Gyroscope\n# The signals are in x,y,z directions\n# Sensor signals are filtered to have only body acceleration\n# excluding the acceleration due to gravity\n# Triaxial acceleration from the accelerometer is total acceleration\nSIGNALS = [\n    \"body_acc_x\",\n    \"body_acc_y\",\n    \"body_acc_z\",\n    \"body_gyro_x\",\n    \"body_gyro_y\",\n    \"body_gyro_z\",\n    \"total_acc_x\",\n    \"total_acc_y\",\n    \"total_acc_z\"\n]","metadata":{"_uuid":"4da1f304-d378-459e-9b68-e8ecd5c8ea6b","_cell_guid":"f0f05f80-c1f4-4a0c-a838-cd989b437c8b","trusted":true,"collapsed":false,"id":"sukQm3UzN2Qz","execution":{"iopub.status.busy":"2025-03-22T11:33:00.171583Z","iopub.execute_input":"2025-03-22T11:33:00.171783Z","iopub.status.idle":"2025-03-22T11:33:00.194682Z","shell.execute_reply.started":"2025-03-22T11:33:00.171766Z","shell.execute_reply":"2025-03-22T11:33:00.193908Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Utility function to read the data from csv file\ndef _read_csv(filename):\n    return pd.read_csv(filename, delim_whitespace=True, header=None)\n\n# Utility function to load the load\ndef load_signals(subset):\n    signals_data = []\n\n    for signal in SIGNALS:\n        filename = f'{DATADIR}/{subset}/Inertial Signals/{signal}_{subset}.txt'\n        signals_data.append(\n            _read_csv(filename).to_numpy()\n        )\n\n    # Transpose is used to change the dimensionality of the output,\n    # aggregating the signals by combination of sample/timestep.\n    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n    return np.transpose(signals_data, (1, 2, 0))","metadata":{"_uuid":"ae21a531-a415-46f2-b456-3c0ded5721e0","_cell_guid":"50922aaa-804a-45aa-9a17-6f3708b1a482","trusted":true,"collapsed":false,"id":"S8Q0Qo3hNzlt","execution":{"iopub.status.busy":"2025-03-22T11:33:00.195717Z","iopub.execute_input":"2025-03-22T11:33:00.195993Z","iopub.status.idle":"2025-03-22T11:33:00.211625Z","shell.execute_reply.started":"2025-03-22T11:33:00.195974Z","shell.execute_reply":"2025-03-22T11:33:00.210956Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def load_y(subset):\n    \"\"\"\n    The objective that we are trying to predict is a integer, from 1 to 6,\n    that represents a human activity. We return a binary representation of\n    every sample objective as a 6 bits vector using One Hot Encoding\n    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n    \"\"\"\n    filename = f'{DATADIR}/{subset}/y_{subset}.txt'\n    y = _read_csv(filename)[0]\n\n    return pd.get_dummies(y).to_numpy(), y.values","metadata":{"_uuid":"808b657c-2a91-42dc-b781-a43e46fb563e","_cell_guid":"250179e0-67c2-419b-b811-cf8d9f17ff2e","trusted":true,"collapsed":false,"id":"K0hFIfemNxgc","execution":{"iopub.status.busy":"2025-03-22T11:33:00.212332Z","iopub.execute_input":"2025-03-22T11:33:00.212554Z","iopub.status.idle":"2025-03-22T11:33:00.226818Z","shell.execute_reply.started":"2025-03-22T11:33:00.212536Z","shell.execute_reply":"2025-03-22T11:33:00.226008Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def load_data():\n    \"\"\"\n    Obtain the dataset from multiple files.\n    Returns: X_train, X_test, y_train, y_test, y_train_raw, y_test_raw\n    \"\"\"\n    X_train, X_test = load_signals('train'), load_signals('test')\n    y_train, y_train_raw = load_y('train')\n    y_test, y_test_raw = load_y('test')\n\n    return X_train, X_test, y_train, y_test, y_train_raw, y_test_raw","metadata":{"_uuid":"60c1aa34-f9f7-4c5a-8a5c-b61594c5b5b9","_cell_guid":"b8bff29f-dd74-438d-a136-02c3489844dc","trusted":true,"collapsed":false,"id":"s-ao3C9ZNv9b","execution":{"iopub.status.busy":"2025-03-22T11:33:00.227681Z","iopub.execute_input":"2025-03-22T11:33:00.227981Z","iopub.status.idle":"2025-03-22T11:33:00.241315Z","shell.execute_reply.started":"2025-03-22T11:33:00.227953Z","shell.execute_reply":"2025-03-22T11:33:00.240689Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Data augmentation functions\ndef add_gaussian_noise(X, sigma=0.01):\n    \"\"\"Add random Gaussian noise to the data.\"\"\"\n    noise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n    return X + noise\n\ndef apply_random_time_shift(X, shift_percent=0.05):\n    \"\"\"Apply random time shifts to the data (Â±5% of window length).\"\"\"\n    X_shifted = np.zeros_like(X)\n\n    for i in range(len(X)):\n        time_steps = X.shape[1]\n        features = X.shape[2]\n        max_shift = int(time_steps * shift_percent)\n\n        # Random shift between -max_shift and max_shift\n        shift = np.random.randint(-max_shift, max_shift + 1)\n\n        # Apply shift\n        for j in range(features):\n            if shift > 0:\n                X_shifted[i, shift:, j] = X[i, :-shift, j]\n                # Pad the beginning\n                X_shifted[i, :shift, j] = X[i, 0, j]\n            elif shift < 0:\n                X_shifted[i, :shift, j] = X[i, -shift:, j]\n                # Pad the end\n                X_shifted[i, shift:, j] = X[i, -1, j]\n            else:\n                X_shifted[i, :, j] = X[i, :, j]\n\n    return X_shifted","metadata":{"_uuid":"ab7900d3-0f6e-4442-ad69-0cda10cc289c","_cell_guid":"bdfae082-1ec7-4f60-b3c1-932452f68997","trusted":true,"collapsed":false,"id":"esmRszbINud8","execution":{"iopub.status.busy":"2025-03-22T11:33:00.262078Z","iopub.execute_input":"2025-03-22T11:33:00.262333Z","iopub.status.idle":"2025-03-22T11:33:00.268605Z","shell.execute_reply.started":"2025-03-22T11:33:00.262312Z","shell.execute_reply":"2025-03-22T11:33:00.267920Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def augment_training_data(X, y):\n    \"\"\"Apply multiple augmentation techniques to training data.\"\"\"\n    # Original data\n    X_augmented = [X]\n    y_augmented = [y]\n\n    # Add Gaussian noise\n    X_noise = add_gaussian_noise(X, sigma=0.01)\n    X_augmented.append(X_noise)\n    y_augmented.append(y)\n\n    # Apply random time shifts\n    X_shifted = apply_random_time_shift(X, shift_percent=0.05)\n    X_augmented.append(X_shifted)\n    y_augmented.append(y)\n\n    # Concatenate all augmented data\n    X_final = np.concatenate(X_augmented, axis=0)\n    y_final = np.concatenate(y_augmented, axis=0)\n\n    print(f\"Original data shape: {X.shape}, Augmented data shape: {X_final.shape}\")\n\n    return X_final, y_final\n\n# Calculate class weights for imbalanced data\ndef calculate_class_weights(y_raw):\n    \"\"\"Calculate inverse frequency weights to address class imbalance.\"\"\"\n    class_weights = class_weight.compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(y_raw),\n        y=y_raw\n    )\n    return dict(enumerate(class_weights))","metadata":{"_uuid":"c5fd380a-a07c-4172-89e4-31bacccfc190","_cell_guid":"62db9760-6119-4768-bb21-bd82bdea4467","trusted":true,"collapsed":false,"id":"2zxiNlqzNshQ","execution":{"iopub.status.busy":"2025-03-22T11:33:00.269739Z","iopub.execute_input":"2025-03-22T11:33:00.270047Z","iopub.status.idle":"2025-03-22T11:33:00.282978Z","shell.execute_reply.started":"2025-03-22T11:33:00.270018Z","shell.execute_reply":"2025-03-22T11:33:00.282173Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Enhanced CSV data processing for external data\ndef process_csv_data(file_path, train_mean=None, train_std=None):\n    \"\"\"\n    Process external CSV data for inference\n    Returns normalized data in the correct shape for the model\n    \"\"\"\n    # Load CSV data with actual columns\n    df = pd.read_csv(file_path)\n\n    # Check for required columns\n    required_columns = ['gFx', 'gFy', 'gFz', 'wx', 'wy', 'wz', 'ax', 'ay', 'az']\n    missing_columns = [col for col in required_columns if col not in df.columns]\n\n    if missing_columns:\n        raise ValueError(f\"Missing required columns: {missing_columns}\")\n\n    # Map CSV columns to required features\n    raw_data = np.hstack([\n        df[['gFx', 'gFy', 'gFz']].values,  # Body acceleration\n        df[['wx', 'wy', 'wz']].values,     # Gyroscope\n        df[['ax', 'ay', 'az']].values      # Total acceleration\n    ])\n\n    # Normalize if mean and std are provided\n    if train_mean is not None and train_std is not None:\n        raw_data = (raw_data - train_mean) / train_std\n\n    # Create windows of 128 timesteps\n    windows = []\n    for i in range(0, len(raw_data) - 127, 32):  # Stride of 32 for less overlap\n        window = raw_data[i:i+128]\n        if len(window) == 128:  # Ensure complete window\n            windows.append(window)\n\n    if not windows:\n        raise ValueError(\"Not enough data to create windows\")\n\n    return np.array(windows)","metadata":{"_uuid":"e1981401-7d41-4ee4-b50b-cb21249b632e","_cell_guid":"da16b8cc-9292-4e7c-83fd-fe0dea14ebae","trusted":true,"collapsed":false,"id":"Z9e0rVtONqlK","execution":{"iopub.status.busy":"2025-03-22T11:33:00.284399Z","iopub.execute_input":"2025-03-22T11:33:00.284602Z","iopub.status.idle":"2025-03-22T11:33:00.301539Z","shell.execute_reply.started":"2025-03-22T11:33:00.284585Z","shell.execute_reply":"2025-03-22T11:33:00.300816Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\n# Temporal smoothing for predictions\ndef apply_temporal_smoothing(predictions, window_size=5):\n    \"\"\"\n    Apply temporal smoothing to model predictions to reduce noise.\n    Uses a sliding window average approach.\n    \"\"\"\n    smoothed_predictions = np.zeros_like(predictions)\n\n    # For each prediction, take the average of surrounding predictions\n    for i in range(len(predictions)):\n        # Define window bounds\n        start = max(0, i - window_size // 2)\n        end = min(len(predictions), i + window_size // 2 + 1)\n\n        # Calculate average within window\n        window_preds = predictions[start:end]\n        smoothed_predictions[i] = np.mean(window_preds, axis=0)\n\n    return smoothed_predictions","metadata":{"_uuid":"0e98b81a-8173-408f-93ed-4c2e5a3f9722","_cell_guid":"28260b63-f6e8-4922-b09b-1535e20d321c","trusted":true,"collapsed":false,"id":"r6s6xwSINoqp","execution":{"iopub.status.busy":"2025-03-22T11:33:00.302430Z","iopub.execute_input":"2025-03-22T11:33:00.302719Z","iopub.status.idle":"2025-03-22T11:33:00.319750Z","shell.execute_reply.started":"2025-03-22T11:33:00.302690Z","shell.execute_reply":"2025-03-22T11:33:00.319115Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Post-processing for predictions\ndef post_process_predictions(predictions, threshold=0.5, smoothing_window=5):\n    \"\"\"\n    Apply post-processing to raw predictions:\n    1. Threshold probabilities\n    2. Apply smoothing to reduce noise\n    3. Return predicted class indices and labels\n    \"\"\"\n    # Apply temporal smoothing\n    smoothed_preds = apply_temporal_smoothing(predictions, smoothing_window)\n\n    # Get predicted class indices\n    pred_indices = np.argmax(smoothed_preds, axis=1)\n\n    # Apply smoothing with a sliding window\n    if len(pred_indices) >= smoothing_window:\n        smoothed_indices = np.zeros_like(pred_indices)\n        for i in range(len(pred_indices)):\n            start = max(0, i - smoothing_window // 2)\n            end = min(len(pred_indices), i + smoothing_window // 2 + 1)\n            window = pred_indices[start:end]\n            # Most common class in window\n            values, counts = np.unique(window, return_counts=True)\n            smoothed_indices[i] = values[np.argmax(counts)]\n        pred_indices = smoothed_indices\n\n    # Map indices to activity labels (add 1 because activities are 1-indexed)\n    pred_labels = [ACTIVITIES[idx + 1] for idx in pred_indices]\n\n    return pred_indices, pred_labels","metadata":{"_uuid":"dffaae24-b4ba-4106-931c-a224430f19a6","_cell_guid":"155a96c3-a451-40dc-a613-e16478de58de","trusted":true,"collapsed":false,"id":"wmuqfP8aNnNl","execution":{"iopub.status.busy":"2025-03-22T11:33:00.320468Z","iopub.execute_input":"2025-03-22T11:33:00.320706Z","iopub.status.idle":"2025-03-22T11:33:00.336094Z","shell.execute_reply.started":"2025-03-22T11:33:00.320677Z","shell.execute_reply":"2025-03-22T11:33:00.335406Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Custom layers for attention mechanisms\nclass TemporalAttention(tf.keras.layers.Layer):\n    \"\"\"Custom attention mechanism for time series data.\"\"\"\n    def __init__(self, units=64, **kwargs):\n        super(TemporalAttention, self).__init__(**kwargs)\n        self.W1 = Dense(units, activation='tanh')\n        self.W2 = Dense(1)\n\n    def call(self, inputs):\n        # Reshape to 2D for dense layer application\n        x = tf.reshape(inputs, (-1, inputs.shape[2]))\n\n        # Apply attention weights calculation\n        x = self.W1(x)\n        x = self.W2(x)\n\n        # Reshape attention weights back to sequence form\n        attention_weights = tf.reshape(x, (-1, inputs.shape[1], 1))\n        attention_weights = tf.nn.softmax(attention_weights, axis=1)\n\n        # Apply attention weights to the input\n        context_vector = inputs * attention_weights\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector\n\n    def get_config(self):\n        config = super().get_config()\n        return config","metadata":{"_uuid":"2f083cb4-2005-49b5-9eb3-d883b492499d","_cell_guid":"214df8ea-6e84-40e4-a96e-7c911f548076","trusted":true,"collapsed":false,"id":"LyeYYMzfNlMM","execution":{"iopub.status.busy":"2025-03-22T11:33:00.337206Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualization functions\ndef plot_confusion_matrix(cm, class_names, title='Confusion Matrix', cmap=None, figsize=(10, 8), normalize=False):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        fmt = '.2f'\n        title += ' (Normalized)'\n    else:\n        fmt = 'd'\n\n    if cmap is None:\n        cmap = plt.cm.Blues\n\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=16)\n    plt.colorbar()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names, rotation=45, fontsize=12)\n    plt.yticks(tick_marks, class_names, fontsize=12)\n\n    # Add text annotations to confusion matrix\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\",\n                fontsize=12)\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=14)\n    plt.xlabel('Predicted label', fontsize=14)\n    return plt","metadata":{"_uuid":"d6314ea1-0387-484b-82d5-f356ef27e760","_cell_guid":"bf41d45c-09dc-470c-ab58-297228c6bcab","trusted":true,"collapsed":false,"id":"UWag-dZcNjWD","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_classification_metrics(y_true, y_pred, class_names, figsize=(12, 8)):\n    \"\"\"\n    Plot precision, recall, and F1 scores from classification results\n    \"\"\"\n    # Calculate metrics\n    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n\n    # Create figure with 3 subplots\n    fig, axes = plt.subplots(1, 3, figsize=figsize)\n\n    # Prepare data\n    metrics = [precision, recall, f1]\n    titles = ['Precision', 'Recall', 'F1 Score']\n\n    # Create bar charts\n    for i, (metric, title) in enumerate(zip(metrics, titles)):\n        axes[i].bar(np.arange(len(class_names)), metric, color='skyblue')\n        axes[i].set_title(title, fontsize=16)\n        axes[i].set_xticks(np.arange(len(class_names)))\n        axes[i].set_xticklabels(class_names, rotation=45, ha='right', fontsize=12)\n        axes[i].set_ylim(0, 1.0)\n        axes[i].set_xlabel('Activity', fontsize=14)\n        axes[i].set_ylabel('Score', fontsize=14)\n\n        # Add value labels\n        for j, v in enumerate(metric):\n            axes[i].text(j, v + 0.02, f'{v:.2f}', ha='center', fontsize=12)\n\n    plt.tight_layout()\n    return fig","metadata":{"_uuid":"0d24a0d3-0284-4f7a-8f93-042332bb7fb3","_cell_guid":"f053dff0-8d0e-4384-a103-9d42a38e0aa3","trusted":true,"collapsed":false,"id":"Q_vMNXgYNhV5","execution":{"iopub.execute_input":"2025-03-22T11:33:00.394045Z","iopub.status.idle":"2025-03-22T11:33:00.410611Z","shell.execute_reply.started":"2025-03-22T11:33:00.394017Z","shell.execute_reply":"2025-03-22T11:33:00.410007Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def plot_combined_metrics(y_true, y_pred, class_names, figsize=(12, 8)):\n    \"\"\"\n    Plot a combined view of precision, recall, and F1 scores\n    \"\"\"\n    # Calculate metrics\n    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n\n    # Create figure\n    plt.figure(figsize=figsize)\n\n    # Set up positions for grouped bars\n    x = np.arange(len(class_names))\n    width = 0.25\n\n    # Create bar groups\n    plt.bar(x - width, precision, width, label='Precision', color='#5DA5DA')\n    plt.bar(x, recall, width, label='Recall', color='#FAA43A')\n    plt.bar(x + width, f1, width, label='F1 Score', color='#60BD68')\n\n    # Add labels and titles\n    plt.title('Classification Performance Metrics by Activity', fontsize=16)\n    plt.xlabel('Activity', fontsize=14)\n    plt.ylabel('Score', fontsize=14)\n    plt.xticks(x, class_names, rotation=45, ha='right', fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.ylim(0, 1.0)\n    plt.legend(fontsize=12)\n\n    plt.tight_layout()\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    return plt\n\n\n# Initializing parameters\nepochs = 1\nbatch_size = 16\nn_hidden = 32","metadata":{"_uuid":"29ad8d9b-5bf3-42a3-9b40-a2a9376d3768","_cell_guid":"246e70f8-4e6b-4044-8554-2b8cd34c19c6","trusted":true,"collapsed":false,"id":"lMRZGeZbNfVc","execution":{"iopub.status.busy":"2025-03-22T11:33:00.411952Z","iopub.execute_input":"2025-03-22T11:33:00.412167Z","iopub.status.idle":"2025-03-22T11:33:00.428146Z","shell.execute_reply.started":"2025-03-22T11:33:00.412149Z","shell.execute_reply":"2025-03-22T11:33:00.427465Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Utility function to count the number of classes\ndef _count_classes(y):\n    return len(set([tuple(category) for category in y]))\n\n# Loading the train and test data\nX_train, X_test, Y_train, Y_test, Y_train_raw, Y_test_raw = load_data()\n\ntimesteps = len(X_train[0])\ninput_dim = len(X_train[0][0])\nn_classes = _count_classes(Y_train)\n\nprint(f\"Timesteps: {timesteps}\")\nprint(f\"Input dimensions: {input_dim}\")\nprint(f\"Number of training samples: {len(X_train)}\")\nprint(f\"Shape of training data: {X_train.shape}\")\n\n# Augment training data - Apply Gaussian noise and random time shifts\nX_train_aug, Y_train_aug = augment_training_data(X_train, Y_train)\n\n# Calculate class weights to address imbalance\nclass_weights = calculate_class_weights(Y_train_raw)\nprint(\"Class weights to address imbalance:\", class_weights)\n\n# Calculate and store normalization parameters for external data processing\ntrain_mean = np.mean(X_train.reshape(-1, input_dim), axis=0)\ntrain_std = np.std(X_train.reshape(-1, input_dim), axis=0)\nnp.save('train_normalization_params.npy', {'mean': train_mean, 'std': train_std})","metadata":{"_uuid":"31c65abb-ea1d-41a1-9aa1-cc72fd662d51","_cell_guid":"35fd2f4b-04eb-441b-9316-98a731f71353","trusted":true,"collapsed":false,"id":"HYNbTIk9NcFu","outputId":"9444b7dc-51c3-4657-d0a4-cfe6e19e20a6","execution":{"iopub.status.busy":"2025-03-22T11:33:00.428999Z","iopub.execute_input":"2025-03-22T11:33:00.429286Z","iopub.status.idle":"2025-03-22T11:33:00.481763Z","shell.execute_reply.started":"2025-03-22T11:33:00.429257Z","shell.execute_reply":"2025-03-22T11:33:00.480702Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"<ipython-input-38-2fc0c20de1db>:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  return pd.read_csv(filename, delim_whitespace=True, header=None)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-ff82d4bcb589>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Loading the train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-239a8ef277cb>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-2fc0c20de1db>\u001b[0m in \u001b[0;36mload_signals\u001b[0;34m(subset)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{DATADIR}/{subset}/Inertial Signals/{signal}_{subset}.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         signals_data.append(\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_read_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-2fc0c20de1db>\u001b[0m in \u001b[0;36m_read_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Utility function to read the data from csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_read_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Utility function to load the load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/human-activity-recognition-with-smartphones/train/Inertial Signals/body_acc_x_train.txt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/human-activity-recognition-with-smartphones/train/Inertial Signals/body_acc_x_train.txt'","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"\"\"\"## Defining LSTM Network model:\"\"\"\n\n# Define callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True,\n    verbose=1\n)\n\nmodel_checkpoint = ModelCheckpoint(\n    'best_lstm_model.keras',\n    monitor='val_accuracy',\n    save_best_only=True,\n    verbose=1\n)\n\n# Add ReduceLROnPlateau callback\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=1e-6,\n    verbose=1\n)","metadata":{"_uuid":"bf26635f-aaf5-45a2-a625-5ff03dd098db","_cell_guid":"57b6aa0b-202f-4649-bbaa-a9f4be988769","trusted":true,"collapsed":false,"id":"3mNjxp-7NZiB","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create LSTM model (for ensemble)\ndef create_lstm_with_attention():\n    inputs = Input(shape=(timesteps, input_dim))\n\n    # First LSTM layer with increased units (128) and return_sequences=True\n    x = Bidirectional(LSTM(128, return_sequences=True))(inputs)\n    x = LayerNormalization()(x)\n    x = SpatialDropout1D(0.5)(x)  # Spatial Dropout instead of regular Dropout\n\n    # Second LSTM layer\n    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n    x = LayerNormalization()(x)\n    x = SpatialDropout1D(0.5)(x)\n\n    # Attention mechanism\n    attn = TemporalAttention(64)(x)\n\n    # Dense layer with ReLU activation and L2 regularization\n    x = Dense(n_hidden, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(attn)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # Output layer with softmax activation\n    outputs = Dense(n_classes, activation='softmax')(x)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        metrics=['accuracy']\n    )\n\n    return model\n\n# Print the summary of the LSTM model (model1)\nprint(\"\\n=== LSTM Model (model1) Summary ===\")\nmodel1 = create_lstm_with_attention()\nmodel1.summary()","metadata":{"_uuid":"1de26d43-0541-4b82-8603-b96ce638b0c9","_cell_guid":"6a9a06df-f563-4eb2-af7e-5513a4db7217","trusted":true,"collapsed":false,"id":"cEXubEQONXrg","outputId":"25b2b30a-9209-46f0-9a9e-f6f7ad3cf923","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an ensemble of LSTM models\ndef create_lstm_ensemble(num_models=3):\n    models = []\n    for i in range(num_models):\n        model = create_lstm_with_attention()\n        models.append(model)\n    return models\n\n# Ensemble prediction function\ndef ensemble_predict(models, X):\n    \"\"\"Combine predictions from multiple models using averaging.\"\"\"\n    predictions = [model.predict(X) for model in models]\n    # Average the predictions\n    ensemble_pred = np.mean(predictions, axis=0)\n    return ensemble_pred\n# Create ensemble of LSTM models\nlstm_ensemble = create_lstm_ensemble(3)\n\n# Train each model in the ensemble\nlstm_histories = []\nfor i, model in enumerate(lstm_ensemble):\n    print(f\"\\nTraining LSTM Ensemble Model {i+1}/{len(lstm_ensemble)}\")\n\n    # Train with early stopping, checkpoints, and reduce LR\n    history = model.fit(\n        X_train_aug,\n        Y_train_aug,\n        batch_size=batch_size,\n        validation_data=(X_test, Y_test),\n        epochs=epochs,\n        class_weight=class_weights,  # Use class weights to address imbalance\n        callbacks=[early_stopping,\n                   ModelCheckpoint(f'best_lstm_ensemble_{i}.keras', monitor='val_accuracy', save_best_only=True),\n                   reduce_lr],\n        verbose=1\n    )\n    lstm_histories.append(history)\n\n    # Save model\n    model.save(f'/kaggle/working/lstm_ensemble_model_{i}.keras')","metadata":{"_uuid":"cfd995a4-0320-4e15-9e8f-d868a6cf653f","_cell_guid":"30cb64ae-41df-413b-99ea-0422deb746d6","trusted":true,"collapsed":false,"id":"Mck0jCoXNRo4","outputId":"18b7a573-1623-4922-d195-314cba3c5d1b","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate ensemble\nensemble_predictions = ensemble_predict(lstm_ensemble, X_test)\ny_pred_classes = np.argmax(ensemble_predictions, axis=1)\ny_true_classes = np.argmax(Y_test, axis=1)\n# Evaluate final ensemble performance\nensemble_accuracy = np.mean([np.equal(y_pred_classes, y_true_classes).astype(float)])\nprint(f\"\\nLSTM Ensemble Accuracy: {ensemble_accuracy:.4f}\")","metadata":{"_uuid":"130628e9-7535-441e-bcad-4dd07bf03898","_cell_guid":"54022791-ce87-4a3c-8190-bd1bb49f7172","trusted":true,"collapsed":false,"id":"j9aSK5y-NNQv","outputId":"d5a39a6b-54e2-4f63-c24d-00c4b8b1c11e","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get activity names for visualization\nactivity_names = [ACTIVITIES[i+1] for i in range(n_classes)]","metadata":{"_uuid":"cbad9424-92ad-493e-a956-de23e6220372","_cell_guid":"8b497d20-31ff-42f3-a702-e8af98e8af00","trusted":true,"collapsed":false,"id":"o8wKyL1jNL2y","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate and display enhanced confusion matrix\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n# Regular confusion matrix\nplot_confusion_matrix(cm, activity_names, title='LSTM Ensemble Confusion Matrix', figsize=(12, 10))\nplt.savefig('/kaggle/working/lstm_ensemble_confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"_uuid":"c2a713d3-ff57-40c1-8550-5b5aad39c7ae","_cell_guid":"2f386c02-d81b-4e68-9cf4-3ba77a9d1cdf","trusted":true,"collapsed":false,"id":"Z9HAD4aHNI3Z","outputId":"83950420-c8de-4ac0-ee3a-9d97c57ce7e3","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Normalized confusion matrix\nplot_confusion_matrix(cm, activity_names, title='LSTM Ensemble Confusion Matrix', figsize=(12, 10), normalize=True)\nplt.savefig('/kaggle/working/lstm_ensemble_confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"_uuid":"53ed4718-d411-4a80-9291-d4cd0c67ea98","_cell_guid":"261ba008-7cac-4cde-b3e6-4a319947e91e","trusted":true,"collapsed":false,"id":"26ySk3CiNHnN","outputId":"4c016a98-22f0-4ad4-d9c9-c521229e5fbb","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display text classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_classes, y_pred_classes, target_names=activity_names))","metadata":{"_uuid":"d6f2a530-9245-4a45-b6db-3538f8744aec","_cell_guid":"c40f4787-0d0d-4e23-b06a-f4344c7e85f2","trusted":true,"collapsed":false,"id":"AThPD1OeNGYX","outputId":"55bdaeb3-b316-402f-bff7-aee7b118ee59","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\"\"\"## Defining CNN-LSTM Network model:\"\"\"\n\n# Reshape data for CNN-LSTM model\nn_steps, n_length = 4, 32\nX_train_cnn = X_train_aug.reshape((X_train_aug.shape[0], n_steps, n_length, input_dim))\nX_test_cnn = X_test.reshape((X_test.shape[0], n_steps, n_length, input_dim))\n\nprint(f\"Reshaped data for CNN-LSTM: {X_train_cnn.shape}\")","metadata":{"_uuid":"fe4c7c65-42c4-4c36-8d00-dd6f74b12d1d","_cell_guid":"10f57c6b-a9a1-4289-9f2b-f3ecc98129b7","trusted":true,"collapsed":false,"id":"5gUfwkLaNBeO","outputId":"ea45ad4a-e2ae-4c68-f4ae-bcd8b22ec39e","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_cnn_lstm_hierarchical():\n    inputs = Input(shape=(n_steps, n_length, input_dim))\n\n    # First level: Improved Depthwise Separable Conv1D for efficiency\n    x = TimeDistributed(SeparableConv1D(filters=128, kernel_size=5, activation='elu', padding='same'))(inputs)\n    x = TimeDistributed(BatchNormalization())(x)\n    x = TimeDistributed(SpatialDropout1D(0.4))(x)\n\n    # Residual connection - first branch\n    skip_connection = x\n\n    # Second level: Extract more complex features\n    x = TimeDistributed(SeparableConv1D(filters=128, kernel_size=3, activation='elu', padding='same'))(x)\n    x = TimeDistributed(BatchNormalization())(x)\n\n    # Third level: Deeper feature extraction\n    x = TimeDistributed(SeparableConv1D(filters=64, kernel_size=3, activation='elu', padding='same'))(x)\n    x = TimeDistributed(BatchNormalization())(x)\n    x = TimeDistributed(SpatialDropout1D(0.4))(x)\n\n    # Apply residual connection if shapes match, otherwise project\n    if skip_connection.shape[-1] == x.shape[-1]:\n        x = Add()([x, skip_connection])\n    else:\n        # Project to match dimensions if needed\n        skip_proj = TimeDistributed(Conv1D(filters=64, kernel_size=1, padding='same'))(skip_connection)\n        x = Add()([x, skip_proj])\n\n    # Hierarchical Feature Extraction: Multi-scale pooling\n    # Small scale features (local patterns)\n    small_pool = TimeDistributed(MaxPooling1D(pool_size=2))(x)\n    small_pool = TimeDistributed(SpatialDropout1D(0.3))(small_pool)\n\n    # Medium scale features\n    med_pool = TimeDistributed(AveragePooling1D(pool_size=3))(x)\n    med_pool = TimeDistributed(SpatialDropout1D(0.3))(med_pool)\n\n    # Larger scale features (global patterns)\n    large_pool = TimeDistributed(GlobalAveragePooling1D())(x)\n    large_pool_reshaped = TimeDistributed(Reshape((1, 64)))(large_pool)\n\n    # Flatten small and medium scale features\n    small_flat = TimeDistributed(Flatten())(small_pool)\n    med_flat = TimeDistributed(Flatten())(med_pool)\n\n    # Combine different scale features\n    combined_features = Concatenate(axis=-1)([small_flat, med_flat])\n\n    # Apply attention to the time dimension\n    attention_layer = TemporalAttention(units=64)(combined_features)\n    attention_weighted = Multiply()([combined_features, attention_layer])\n\n    # First LSTM layer processes the combined features\n    lstm_small = Bidirectional(LSTM(96, return_sequences=True, recurrent_dropout=0.2))(attention_weighted)\n    lstm_small = LayerNormalization()(lstm_small)\n    lstm_small = SpatialDropout1D(0.3)(lstm_small)\n\n    # Second LSTM layer with attention\n    lstm_attention = TemporalAttention(units=32)(lstm_small)\n    lstm_attention_weighted = Multiply()([lstm_small, lstm_attention])\n\n    # Final LSTM layer\n    lstm_final = Bidirectional(LSTM(64, recurrent_dropout=0.2))(lstm_attention_weighted)\n    lstm_final = LayerNormalization()(lstm_final)\n\n    # Dense layers with residual connections\n    x = Dense(128, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(lstm_final)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n\n    # Second dense layer\n    y = Dense(64, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.005))(x)\n    y = BatchNormalization()(y)\n    y = Dropout(0.4)(y)\n\n    # Residual connection in dense layers\n    # Project x to match y's dimensions\n    x_proj = Dense(64)(x)\n    y = Add()([y, x_proj])\n\n    # Output layer\n    outputs = Dense(n_classes, activation='softmax')(y)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n        metrics=['accuracy']\n    )\n\n    return model\n\n# Print the summary of the CNN-LSTM model (model2)\nprint(\"\\n=== CNN-LSTM Model (model2) Summary ===\")\nmodel2 = create_cnn_lstm_hierarchical()\nmodel2.summary()","metadata":{"_uuid":"3f035c53-2f0f-43bc-a155-2067d3a83583","_cell_guid":"a0ef5398-adc4-432e-af92-0ccfcf169e76","trusted":true,"collapsed":false,"id":"NCYk4dZuM-Sk","outputId":"c10bd8b9-ecd9-49c4-925b-2f45e1431039","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an ensemble of CNN-LSTM models\ndef create_cnn_lstm_ensemble(num_models=3):\n    models = []\n    for i in range(num_models):\n        model = create_cnn_lstm_hierarchical()\n        models.append(model)\n    return models\n\n# Create ensemble of CNN-LSTM models\ncnn_lstm_ensemble = create_cnn_lstm_ensemble(3)\n\n# Modify early stopping to be more patient\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    patience=15,  # Increased patience\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Learning rate scheduler - Cosine decay with warm restarts\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=5,\n    min_lr=0.00001,\n    verbose=1\n)","metadata":{"_uuid":"430faf5d-03f3-4018-832d-bee675db1526","_cell_guid":"e404b937-03d3-4f37-8fa6-6b16e259b128","trusted":true,"collapsed":false,"id":"hhk09siSM6ni","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply more advanced data augmentation for training\ndef advanced_augment_training_data(X, y):\n    \"\"\"Apply enhanced data augmentation for CNN-LSTM model\"\"\"\n    X_aug = X.copy()\n    y_aug = y.copy()\n\n    # Add Gaussian noise with varying intensities\n    for sigma in [0.01, 0.02, 0.03]:\n        X_noise = add_gaussian_noise(X, sigma=sigma)\n        X_aug = np.vstack((X_aug, X_noise))\n        y_aug = np.vstack((y_aug, y))\n\n    # Apply time shifts with varying intensities\n    for shift in [0.05, 0.08, 0.1]:\n        X_shift = apply_random_time_shift(X, shift_percent=shift)\n        X_aug = np.vstack((X_aug, X_shift))\n        y_aug = np.vstack((y_aug, y))\n\n    # Apply magnitude scaling (simulate different sensor sensitivities)\n    for scale in [0.9, 1.1]:\n        X_scale = X * scale\n        X_aug = np.vstack((X_aug, X_scale))\n        y_aug = np.vstack((y_aug, y))\n\n    # Apply more augmentation for underrepresented classes\n    class_counts = np.sum(y, axis=0)\n    max_count = np.max(class_counts)\n\n    for class_idx in range(len(class_counts)):\n        if class_counts[class_idx] < max_count * 0.5:  # Heavily underrepresented\n            # Find samples of this class\n            class_indices = np.where(y[:, class_idx] == 1)[0]\n            if len(class_indices) > 0:\n                # Additional augmentation for underrepresented classes\n                class_samples = X[class_indices]\n                class_labels = y[class_indices]\n\n                # Create more variations\n                for _ in range(3):  # Create more samples for underrepresented classes\n                    # Combine multiple augmentations\n                    augmented = add_gaussian_noise(apply_random_time_shift(class_samples), sigma=0.02)\n                    X_aug = np.vstack((X_aug, augmented))\n                    y_aug = np.vstack((y_aug, class_labels))\n\n    return X_aug, y_aug","metadata":{"_uuid":"5c8b3708-eea1-4866-9f00-5c650eb8c529","_cell_guid":"8905c491-486c-419f-8353-617084015d1b","trusted":true,"collapsed":false,"id":"RNwGvam3M2SX","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train each model in the ensemble with enhanced augmentation\ncnn_lstm_histories = []\nfor i, model in enumerate(cnn_lstm_ensemble):\n    print(f\"\\nTraining Enhanced CNN-LSTM Ensemble Model {i+1}/{len(cnn_lstm_ensemble)}\")\n\n    # Apply advanced augmentation\n    X_train_cnn_aug, Y_train_cnn_aug = advanced_augment_training_data(X_train_cnn, Y_train_aug)\n\n    # Define checkpoint for this model\n    checkpoint = ModelCheckpoint(\n        f'/kaggle/working/best_cnn_lstm_ensemble_{i}.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        verbose=1\n    )\n\n    # Train with early stopping, checkpoints, and reduce LR\n    history = model.fit(\n        X_train_cnn_aug,\n        Y_train_cnn_aug,\n        batch_size=32,  # Smaller batch size for better generalization\n        validation_data=(X_test_cnn, Y_test),\n        epochs=epochs,  # Allow more epochs with early stopping\n        class_weight=class_weights,  # Use class weights to address imbalance\n        callbacks=[early_stopping, checkpoint, reduce_lr],\n        verbose=1\n    )\n    cnn_lstm_histories.append(history)\n\n    # Save model\n    model.save(f'/kaggle/working/enhanced_cnn_lstm_ensemble_model_{i}.keras')","metadata":{"_uuid":"85c0d922-fc9f-46cd-9c1d-1b20ef7d5dbb","_cell_guid":"ecee6279-360a-48c0-8124-cd259eec635c","trusted":true,"collapsed":false,"id":"4-6gSAk2M0LV","outputId":"fb782b45-736f-4dbf-fce3-bf8198053706","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate ensemble\nensemble_predictions = ensemble_predict(cnn_lstm_ensemble, X_test_cnn)\n\n# Apply temporal smoothing to ensemble predictions\nsmoothed_predictions = apply_temporal_smoothing(ensemble_predictions)\ny_pred_classes = np.argmax(smoothed_predictions, axis=1)\n\n# Evaluate final ensemble performance\nensemble_accuracy = np.mean([np.equal(y_pred_classes, y_true_classes).astype(float)])\nprint(f\"\\nCNN-LSTM Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n\n# Generate and display enhanced confusion matrix for CNN-LSTM\ncm = confusion_matrix(y_true_classes, y_pred_classes)","metadata":{"_uuid":"297c9c8b-b2e0-41ab-a1ad-9012578254fe","_cell_guid":"271299b1-0513-4df5-b1e1-e7ab9f0b7e12","trusted":true,"collapsed":false,"id":"pA4sKivyMxfJ","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Regular confusion matrix\nplot_confusion_matrix(cm, activity_names, title='CNN-LSTM Ensemble Confusion Matrix', figsize=(12, 10))\nplt.savefig('/kaggle/working/cnn_lstm_ensemble_confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"_uuid":"a4131cf5-77d6-4237-a613-8e8e00c4b76e","_cell_guid":"49fa3185-04f5-41e6-af3f-95d73f2eb69c","trusted":true,"collapsed":false,"id":"9M8C8OhgMvuS","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalized confusion matrix\nplot_confusion_matrix(cm, activity_names, title='CNN-LSTM Ensemble Confusion Matrix', figsize=(12, 10), normalize=True)\nplt.savefig('/kaggle/working/cnn_lstm_ensemble_confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"_uuid":"1aab3d4e-9da5-406c-9046-b4eca0d2ba90","_cell_guid":"bedbe807-e2b0-4e20-b199-ec4a2c56136e","trusted":true,"collapsed":false,"id":"anQW_87-MuLG","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display text classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_classes, y_pred_classes, target_names=activity_names))","metadata":{"_uuid":"874e51e5-441e-4134-bb2c-808193d02bc9","_cell_guid":"2808bb85-fa6e-4fd0-9dce-3f86fed38aff","trusted":true,"collapsed":false,"id":"FjdPk29IMssG","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_model_history(histories, model_name):\n    \"\"\"\n    Plots the training and validation accuracy and loss curves for ensemble models.\n\n    Args:\n        histories: List of training history objects returned by model.fit.\n        model_name: The name of the model type (e.g., \"LSTM\", \"CNN-LSTM\").\n    \"\"\"\n    # Check if histories list is empty\n    if not histories:\n        print(f\"Warning: No training histories found for {model_name}\")\n        return\n\n    # Ensure all histories have the expected keys\n    required_keys = ['accuracy', 'val_accuracy', 'loss', 'val_loss']\n    for i, h in enumerate(histories):\n        if not all(key in h.history for key in required_keys):\n            print(f\"Warning: Model {i+1} history is missing required keys. Skipping plot for {model_name}.\")\n            return\n\n    # Check if all histories have consistent lengths\n    first_history_len = len(histories[0].history['accuracy'])\n    if not all(len(h.history['accuracy']) == first_history_len for h in histories):\n        print(f\"Warning: Inconsistent history lengths for {model_name}. Adjusting to shortest length.\")\n        min_len = min(len(h.history['accuracy']) for h in histories)\n\n        # Calculate average history using the minimum length\n        avg_history = {\n            'accuracy': np.mean([[h.history['accuracy'][i] for h in histories] for i in range(min_len)], axis=1),\n            'val_accuracy': np.mean([[h.history['val_accuracy'][i] for h in histories] for i in range(min_len)], axis=1),\n            'loss': np.mean([[h.history['loss'][i] for h in histories] for i in range(min_len)], axis=1),\n            'val_loss': np.mean([[h.history['val_loss'][i] for h in histories] for i in range(min_len)], axis=1),\n        }\n    else:\n        # Calculate average history as before\n        avg_history = {\n            'accuracy': np.mean([[h.history['accuracy'][i] for h in histories] for i in range(first_history_len)], axis=1),\n            'val_accuracy': np.mean([[h.history['val_accuracy'][i] for h in histories] for i in range(first_history_len)], axis=1),\n            'loss': np.mean([[h.history['loss'][i] for h in histories] for i in range(first_history_len)], axis=1),\n            'val_loss': np.mean([[h.history['val_loss'][i] for h in histories] for i in range(first_history_len)], axis=1),\n        }\n\n    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n\n    # Plot training & validation accuracy values\n    axs[0].plot(avg_history['accuracy'], linewidth=2, label='Avg Train')\n    axs[0].plot(avg_history['val_accuracy'], linewidth=2, label='Avg Validation')\n\n    # Plot individual model histories\n    for i, hist in enumerate(histories):\n        # Ensure we only plot up to the calculated length\n        hist_len = len(hist.history['accuracy'])\n        actual_len = min(hist_len, len(avg_history['accuracy']))\n\n        axs[0].plot(hist.history['accuracy'][:actual_len], linewidth=1, alpha=0.3, linestyle='--', label=f'Model {i+1} Train')\n        axs[0].plot(hist.history['val_accuracy'][:actual_len], linewidth=1, alpha=0.3, linestyle='--', label=f'Model {i+1} Val')\n\n    axs[0].set_title(f'{model_name} Ensemble Model Accuracy', fontsize=16)\n    axs[0].set_ylabel('Accuracy', fontsize=14)\n    axs[0].set_xlabel('Epoch', fontsize=14)\n    axs[0].tick_params(axis='both', which='major', labelsize=12)\n    axs[0].legend(fontsize=10)\n    axs[0].grid(True, linestyle='--', alpha=0.6)\n\n    # Plot training & validation loss values\n    axs[1].plot(avg_history['loss'], linewidth=2, label='Avg Train')\n    axs[1].plot(avg_history['val_loss'], linewidth=2, label='Avg Validation')\n\n    # Plot individual model histories\n    for i, hist in enumerate(histories):\n        # Ensure we only plot up to the calculated length\n        hist_len = len(hist.history['loss'])\n        actual_len = min(hist_len, len(avg_history['loss']))\n\n        axs[1].plot(hist.history['loss'][:actual_len], linewidth=1, alpha=0.3, linestyle='--', label=f'Model {i+1} Train')\n        axs[1].plot(hist.history['val_loss'][:actual_len], linewidth=1, alpha=0.3, linestyle='--', label=f'Model {i+1} Val')\n\n    axs[1].set_title(f'{model_name} Ensemble Model Loss', fontsize=16)\n    axs[1].set_ylabel('Loss', fontsize=14)\n    axs[1].set_xlabel('Epoch', fontsize=14)\n    axs[1].tick_params(axis='both', which='major', labelsize=12)\n    axs[1].legend(fontsize=10)\n    axs[1].grid(True, linestyle='--', alpha=0.6)\n\n    plt.tight_layout()\n    fig.savefig(f'/kaggle/working/{model_name.lower().replace(\" \", \"_\")}_ensemble_training_history.png', dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"_uuid":"fade45d7-c3eb-4a10-8d8c-78e64da7c1f2","_cell_guid":"e3a212ed-5da8-473c-9eb9-65a968f06417","trusted":true,"collapsed":false,"id":"Q7JcRBusMmgS","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the training history graphs\nplot_model_history(lstm_histories, \"Improved LSTM\")\nplot_model_history(cnn_lstm_histories, \"Improved CNN-LSTM\")\n\n# Model performance comparison\nlstm_acc = ensemble_accuracy\ncnn_lstm_acc = np.mean([np.equal(y_pred_classes, y_true_classes).astype(float)])\n\n# Compare model performance with a bar chart\nplt.figure(figsize=(10, 6))\nmodels = ['LSTM Ensemble', 'CNN-LSTM Ensemble']\naccuracies = [lstm_acc, cnn_lstm_acc]\n# Create a gradient-colored bar chart\nplt.bar(models, accuracies, color=['#3498db', '#2ecc71'], alpha=0.8, width=0.6)\nplt.title('Ensemble Model Accuracy Comparison', fontsize=16)\nplt.ylabel('Test Accuracy', fontsize=14)\nplt.ylim(0, 1.0)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)","metadata":{"_uuid":"d37aa19a-0e32-4ba4-be06-3b9f9cce5bea","_cell_guid":"73f5b200-e12b-4539-8bbf-5aaf09674bba","trusted":true,"collapsed":false,"id":"PgMjrcJcMgtg","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add value labels\nfor i, v in enumerate(accuracies):\n    plt.text(i, v + 0.02, f'{v:.4f}', ha='center', fontsize=12, fontweight='bold')\n\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.savefig('/kaggle/working/ensemble_model_accuracy_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"_uuid":"6f76f4db-2ec4-45a5-8378-55ce7f7190c1","_cell_guid":"9df260c9-0d53-46fe-a6a1-7b3577d5583d","trusted":true,"collapsed":false,"id":"RAu6NDIyMfhD","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}